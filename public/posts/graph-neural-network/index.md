# 圖神經網絡的由來：從傅立葉轉換到圖卷積

當我們談論深度學習的革命性突破時，卷積神經網絡（CNN）無疑是其中最耀眼的明星之一，然而，CNN 假設**資料必須具有規則的網格結構**，這個假設在處理現實世界中大量的非歐幾里得資料時顯得力不從心，所以圖神經網絡（GNN）是如何從經典的傅立葉轉換中汲取靈感，建立起在圖結構上進行卷積運算的理論基礎。

---

# 背景問題

## CNN 在圖結構上的困境

卷積神經網絡之所以能在影像處理領域大放異彩，是因為影像本質上是一個二維的規則網格。每個像素都有固定的鄰居數量，且這些鄰居的相對位置是確定的。CNN 利用這種規律性，透過滑動視窗的方式在整張影像上共享同一組濾波器權重，這就是所謂的「平移不變性」。

然而，當我們面對社交網絡、分子結構、交通網絡或知識圖譜時，情況變得截然不同。這些資料天然地以圖（Graph）的形式存在，具有以下特性：

- **節點數量不固定**：每個圖可能包含不同數量的節點
- **鄰居數量不一致**：不同節點可能連接到不同數量的鄰居
- **缺乏空間順序**：節點的鄰居之間沒有固定的排列順序
- **拓撲結構多變**：圖的連接模式可以是任意的

這些特性使得傳統 CNN 的卷積核無法直接套用。試想，當一個節點有 3 個鄰居，另一個節點有 7 個鄰居時，我們該如何定義一個統一的 $3 \times 3$ 卷積核？

## GNN 的解決思路

圖神經網絡的核心洞見在於：與其嘗試在空間域中硬套卷積的概念，不如回到卷積的數學本質。在信號處理中，卷積可以透過傅立葉轉換轉化為頻譜域中的逐點相乘。這個性質被稱為「卷積定理」，數學上表達為：

$$f * g = \mathcal{F}^{-1}\left(\mathcal{F}(f) \cdot \mathcal{F}(g)\right)$$

其中 $\mathcal{F}$ 表示傅立葉轉換，$\mathcal{F}^{-1}$ 表示逆傅立葉轉換。

GNN 的策略是：既然圖上沒有天然的「平移」概念，那就繞道頻譜域。具體而言，GNN 將卷積運算類比為：

1. 將圖上的信號轉換到頻譜域（圖傅立葉轉換）
2. 在頻譜域中應用濾波器（逐點相乘）
3. 將結果轉換回圖的節點域（逆圖傅立葉轉換）

這裡的關鍵問題是：圖上的「傅立葉轉換」該如何定義？答案藏在圖的拉普拉斯矩陣中。

---

# 傳統傅立葉轉換

在深入圖傅立葉轉換之前，讓我們先回顧經典傅立葉轉換的核心概念，這將幫助我們理解 GNN 是如何進行類比的。

## 頻率與頻率模式

傅立葉分析的核心思想是：任何信號都可以分解成不同頻率的正弦波和餘弦波的疊加。這裡的「頻率」描述的是信號變化的快慢程度：

- **低頻成分**：信號變化緩慢、平滑，代表信號的整體趨勢
- **高頻成分**：信號變化劇烈、震盪，代表信號的細節和邊緣

每個頻率對應一個特定的「頻率模式」，在經典傅立葉分析中就是正弦函數 $\sin(2\pi f t)$ 或複指數函數 $e^{i2\pi ft}$。這些函數形成了一組「基底」，就像三維空間中的 x、y、z 軸一樣，任何信號都可以用這組基底的線性組合來表示。

## 頻率係數

當我們對一個信號進行傅立葉轉換時，得到的是一系列「頻率係數」。每個係數告訴我們：原始信號中包含多少該頻率的成分。

$$\hat{f}(\omega) = \int_{-\infty}^{\infty} f(t) \cdot e^{-i\omega t} \, dt$$

這個積分本質上是在計算原始信號 $f(t)$ 與每個頻率模式 $e^{-i\omega t}$ 之間的「相似程度」。係數越大，表示原始信號中該頻率的成分越強。

## 濾波器

有了頻率分解，我們就可以選擇性地增強或抑制某些頻率成分，這就是「濾波」的概念：

- **低通濾波器**：保留低頻、去除高頻，效果是使信號變平滑
- **高通濾波器**：保留高頻、去除低頻，效果是突出信號的變化和邊緣
- **帶通濾波器**：只保留特定頻率範圍的成分

濾波的操作非常直觀：在頻譜域中，將信號的頻率係數與濾波器函數逐點相乘。想要去除某個頻率？只需將該頻率的濾波器值設為 0。

這種「轉換到頻譜域 → 濾波 → 轉換回時域」的流程，正是 GNN 在圖結構上進行卷積的藍圖。

如果我們仔細審視傳統傅立葉轉換的架構，會發現每一個核心概念都能在圖卷積中找到對應物。

在傳統傅立葉分析中，我們有一組正交的頻率模式（正弦與餘弦函數）作為基底，任何信號都能分解為這些基底的線性組合；在圖卷積中，這組基底由拉普拉斯矩陣的特徵向量所取代，每個特徵向量描述了一種信號在圖上分布的模式，對應較小特徵值的特徵向量在相鄰節點間變化平緩，而對應較大特徵值的特徵向量則呈現劇烈的正負交替。傳統分析中的頻率描述信號震盪的快慢，而圖上的「頻率」則由特徵值來表徵，衡量的是信號在相鄰節點間變化的劇烈程度。

傅立葉轉換將時域信號投影到頻率基底上得到頻率係數，圖傅立葉轉換則是將節點信號投影到特徵向量基底上得到對應的係數，這些係數反映了原始信號中包含多少該特徵向量所代表的變化模式，係數越大表示信號越接近該模式的分布形態。

濾波器在傳統分析中是定義在頻率軸上的函數，決定每個頻率成分的增益或衰減，例如低通濾波器讓低頻通過而壓制高頻，使信號變得平滑；在圖上，濾波器是定義在特徵值上的函數，同樣透過對不同特徵值給予不同的權重來選擇性地保留或抑制特定的變化模式，若我們設計一個隨特徵值增大而衰減的濾波器，由於較大的特徵值對應較高的圖頻率，這樣的設計會保留低頻成分、壓制高頻成分，正是圖上的低通濾波器，能使相鄰節點的特徵趨於一致，達到平滑化的效果。

最後，逆傅立葉轉換將處理過的頻率成分重新合成為時域信號，而逆圖傅立葉轉換則將濾波後的係數透過特徵向量基底重建回節點上的信號。這種一一對應的結構，使得我們能夠將傅立葉分析的整套理論框架完整地移植到圖結構上，為圖神經網絡的卷積運算奠定了數學基礎。

---

# 圖卷積

現在讓我們透過一個具體的三節點圖來展示圖卷積的完整流程。

## 問題設定

假設我們有一個包含三個節點的簡單圖，節點編號為 0、1、2。節點之間的連接關係為：

- 節點 0 連接到節點 1
- 節點 1 連接到節點 2
- 節點 0 連接到節點 2

這形成一個完全連通的三角形圖。每個節點上有一個純量特徵值，我們以向量形式表示為：

$$\mathbf{x} = \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}$$

其中 $x_0 = 1$（節點 0 的特徵）、$x_1 = 2$（節點 1 的特徵）、$x_2 = 3$（節點 2 的特徵）。

對應的鄰接矩陣為：

$$A = \begin{bmatrix} 0 & 1 & 1 \\ 1 & 0 & 1 \\ 1 & 1 & 0 \end{bmatrix}$$

其中 $A_{ij} = 1$ 表示節點 $i$ 和節點 $j$ 之間有連接。

---

### 建立傅立葉基底

在傳統傅立葉分析中，正弦和餘弦函數作為基底。在圖上，我們需要找到類似的基底函數，而這些基底來自於圖的拉普拉斯矩陣的特徵向量。

**步驟一：計算度數矩陣**

度數矩陣 $D$ 是一個對角矩陣，第 $i$ 個對角元素表示節點 $i$ 的度數（連接的邊數）。

$$D = \begin{bmatrix} 2 & 0 & 0 \\ 0 & 2 & 0 \\ 0 & 0 & 2 \end{bmatrix}$$

每個節點都連接到其他兩個節點，因此度數都是 2。

**步驟二：計算拉普拉斯矩陣**

非正規化的拉普拉斯矩陣定義為 $L = D - A$：

$$L = \begin{bmatrix} 2 & 0 & 0 \\ 0 & 2 & 0 \\ 0 & 0 & 2 \end{bmatrix} - \begin{bmatrix} 0 & 1 & 1 \\ 1 & 0 & 1 \\ 1 & 1 & 0 \end{bmatrix} = \begin{bmatrix} 2 & -1 & -1 \\ -1 & 2 & -1 \\ -1 & -1 & 2 \end{bmatrix}$$

拉普拉斯矩陣在圖論中扮演著核心角色。它的物理意義可以理解為：描述每個節點的值與其鄰居平均值之間的差異。當我們將 $L$ 作用於信號向量 $\mathbf{x}$ 時，得到的結果反映了信號在圖上的「不平滑程度」。

**步驟三：特徵分解**

對拉普拉斯矩陣進行特徵分解，求解 $L\mathbf{u} = \lambda\mathbf{u}$。

對於我們的 $3 \times 3$ 拉普拉斯矩陣，特徵值和對應的特徵向量為：

**特徵值 $\lambda_0 = 0$：**

$$\mathbf{u}_0 = \frac{1}{\sqrt{3}}\begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix} \approx \begin{bmatrix} 0.577 \\ 0.577 \\ 0.577 \end{bmatrix}$$

**特徵值 $\lambda_1 = 3$：**

$$\mathbf{u}_1 = \frac{1}{\sqrt{2}}\begin{bmatrix} 1 \\ 0 \\ -1 \end{bmatrix} \approx \begin{bmatrix} 0.707 \\ 0 \\ -0.707 \end{bmatrix}$$

**特徵值 $\lambda_2 = 3$：**

$$\mathbf{u}_2 = \frac{1}{\sqrt{6}}\begin{bmatrix} 1 \\ -2 \\ 1 \end{bmatrix} \approx \begin{bmatrix} 0.408 \\ -0.816 \\ 0.408 \end{bmatrix}$$

這些特徵向量組成了圖上的傅立葉基底，我們將它們排列成矩陣 $U$：

$$U = \begin{bmatrix} \mathbf{u}_0 & \mathbf{u}_1 & \mathbf{u}_2 \end{bmatrix} = \begin{bmatrix} 0.577 & 0.707 & 0.408 \\ 0.577 & 0 & -0.816 \\ 0.577 & -0.707 & 0.408 \end{bmatrix}$$

**特徵值與頻率的關係：**

- **$\lambda_0 = 0$**：對應最低頻率（直流成分）。特徵向量 $\mathbf{u}_0$ 在所有節點上的值相同，代表圖上的常數信號，完全平滑，沒有任何變化。
- **$\lambda_1 = \lambda_2 = 3$**：對應較高頻率。這些特徵向量在相鄰節點上呈現正負交替的模式，代表信號的變化和振盪。

特徵值越大，對應的特徵向量在圖上變化越劇烈，因此可以將特徵值視為「圖頻率」的度量。

---

### 圖傅立葉轉換

有了傅立葉基底，我們就可以將圖上的信號從節點域轉換到頻譜域。圖傅立葉轉換定義為：

$$\hat{\mathbf{x}} = U^T \mathbf{x}$$

將我們的信號 $\mathbf{x} = [1, 2, 3]^T$ 代入計算：

$$\hat{\mathbf{x}} = \begin{bmatrix} 0.577 & 0.577 & 0.577 \\ 0.707 & 0 & -0.707 \\ 0.408 & -0.816 & 0.408 \end{bmatrix} \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}$$

逐項計算：

- $\hat{x}_0 = 0.577 \times 1 + 0.577 \times 2 + 0.577 \times 3 = 0.577 \times 6 = 3.464$
- $\hat{x}_1 = 0.707 \times 1 + 0 \times 2 + (-0.707) \times 3 = 0.707 - 2.121 = -1.414$
- $\hat{x}_2 = 0.408 \times 1 + (-0.816) \times 2 + 0.408 \times 3 = 0.408 - 1.632 + 1.224 = 0$

因此：

$$\hat{\mathbf{x}} = \begin{bmatrix} 3.464 \\ -1.414 \\ 0 \end{bmatrix}$$

**頻譜分析：**

這三個頻率係數告訴我們原始信號的組成：

- **$\hat{x}_0 = 3.464$（低頻/直流成分）**：這是最大的係數，表示信號的主要成分是「整體平均水平」。原始信號 $[1, 2, 3]$ 的平均值為 2，這個強烈的低頻成分反映了這一事實。
- **$\hat{x}_1 = -1.414$（高頻成分）**：這個非零的係數表示信號在圖上確實存在變化。負值表示這個變化模式與 $\mathbf{u}_1$ 的方向相反。
- **$\hat{x}_2 = 0$（高頻成分）**：這個係數為零，意味著信號中不包含 $\mathbf{u}_2$ 這種變化模式。

**結論：這個信號主要由低頻成分構成（係數 3.464），伴隨著一個中等強度的高頻成分（係數 -1.414），整體上是一個相對平滑但有一定變化趨勢的信號。**

---

### 定義以及執行濾波

現在我們可以在頻譜域中設計濾波器來修改信號。濾波器是一個對角矩陣 $g(\Lambda)$，其對角線上的元素決定了每個頻率成分的縮放係數：

$$g(\Lambda) = \begin{bmatrix} g(\lambda_0) & 0 & 0 \\ 0 & g(\lambda_1) & 0 \\ 0 & 0 & g(\lambda_2) \end{bmatrix}$$

讓我們設計一個**低通濾波器**，目標是保留低頻成分、抑制高頻成分。一個簡單的設計是：

$$g(\lambda) = e^{-\lambda}$$

對於我們的特徵值：

- $g(\lambda_0) = g(0) = e^{0} = 1$（完全保留低頻）
- $g(\lambda_1) = g(3) = e^{-3} \approx 0.050$（大幅衰減高頻）
- $g(\lambda_2) = g(3) = e^{-3} \approx 0.050$（大幅衰減高頻）

濾波器矩陣為：

$$g(\Lambda) = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 0.050 & 0 \\ 0 & 0 & 0.050 \end{bmatrix}$$

**執行濾波：**

在頻譜域中，濾波操作就是簡單的逐元素相乘：

$$\hat{\mathbf{x}}_{\text{filtered}} = g(\Lambda) \cdot \hat{\mathbf{x}} = \begin{bmatrix} 1 \times 3.464 \\ 0.050 \times (-1.414) \\ 0.050 \times 0 \end{bmatrix} = \begin{bmatrix} 3.464 \\ -0.071 \\ 0 \end{bmatrix}$$

濾波後，低頻成分 3.464 被完整保留，而高頻成分 -1.414 被大幅壓縮至 -0.071。

---

### 逆圖傅立葉轉換

最後一步是將濾波後的頻譜係數轉換回節點域，得到卷積後的輸出。逆圖傅立葉轉換定義為：

$$\mathbf{x}_{\text{output}} = U \hat{\mathbf{x}}_{\text{filtered}}$$

計算：

$$\mathbf{x}_{\text{output}} = \begin{bmatrix} 0.577 & 0.707 & 0.408 \\ 0.577 & 0 & -0.816 \\ 0.577 & -0.707 & 0.408 \end{bmatrix} \begin{bmatrix} 3.464 \\ -0.071 \\ 0 \end{bmatrix}$$

逐項計算：

- $x_{\text{out},0} = 0.577 \times 3.464 + 0.707 \times (-0.071) + 0.408 \times 0 = 1.999 - 0.050 = 1.949$
- $x_{\text{out},1} = 0.577 \times 3.464 + 0 \times (-0.071) + (-0.816) \times 0 = 1.999$
- $x_{\text{out},2} = 0.577 \times 3.464 + (-0.707) \times (-0.071) + 0.408 \times 0 = 1.999 + 0.050 = 2.049$

因此，卷積後的輸出為：

$$\mathbf{x}_{\text{output}} \approx \begin{bmatrix} 1.95 \\ 2.00 \\ 2.05 \end{bmatrix}$$

**結果分析：**

對比原始信號 $[1, 2, 3]$ 和輸出信號 $[1.95, 2.00, 2.05]$：

- 原始信號的範圍是 1 到 3，變化幅度為 2
- 輸出信號的範圍約為 1.95 到 2.05，變化幅度僅約 0.1
- 所有節點的值都趨近於平均值 2

這正是低通濾波器的預期效果：去除高頻變化，使信號變得平滑。在圖的語境下，這意味著相鄰節點的特徵值變得更加相似，信號在圖上的變化被抑制。

---

# 頻譜域卷積

透過上述的完整流程，我們可以將圖上的頻譜域卷積形式化地表達為：

$$\mathbf{x}_{\text{output}} = U \cdot g(\Lambda) \cdot U^T \cdot \mathbf{x}$$

或等價地寫成：

$$\mathbf{x}_{\text{output}} = U g(\Lambda) U^T \mathbf{x}$$

這個公式的每一部分都有明確的意義：

- **$U^T \mathbf{x}$**：圖傅立葉轉換，將信號從節點域投影到頻譜域
- **$g(\Lambda)$**：頻譜濾波器，在頻譜域中對不同頻率成分進行加權
- **$U \cdot (\cdot)$**：逆圖傅立葉轉換，將處理後的頻譜重新合成為節點域信號

這個框架的優美之處在於，透過改變 $g(\Lambda)$ 的設計，我們可以實現各種不同的卷積效果。而在圖神經網絡中，$g(\Lambda)$ 的參數正是透過訓練學習得到的，使得網絡能夠自動發現對特定任務最有用的頻率成分組合。

**從頻譜域到空間域的演進：**

早期的圖神經網絡確實採用這種頻譜域卷積的方法，但它存在一些實際問題：

- **計算複雜度高**：特徵分解的時間複雜度為 $O(n^3)$，對於大規模圖不可行
- **濾波器不具有空間局部性**：頻譜域的濾波器會影響整個圖，缺乏類似 CNN 的局部感受野
- **依賴於特定圖結構**：學到的濾波器無法直接遷移到不同結構的圖

這些問題促使研究者們發展出了各種近似方法，如 ChebNet 使用切比雪夫多項式近似濾波器，最終導向了如今廣泛使用的消息傳遞框架（如 GCN、GraphSAGE、GAT），這些方法雖然在形式上看起來與頻譜卷積很不同，但其理論根基仍然可以追溯到本文介紹的圖傅立葉分析框架。
